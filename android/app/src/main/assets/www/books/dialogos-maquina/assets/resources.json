{
  "bookId": "dialogos-maquina",
  "lastUpdate": "2025-12-20",
  "categories": [
    {
      "id": "libros-filosofia",
      "name": "Libros: Filosofía de la Mente",
      "description": "Obras fundamentales sobre conciencia, mente y experiencia",
      "resources": [
        {
          "id": "nagel-bat",
          "title": "What Is It Like to Be a Bat?",
          "author": "Thomas Nagel",
          "type": "libro",
          "url": "https://www.jstor.org/stable/2183914",
          "description": "Paper filosófico clásico sobre la subjetividad y el problema de las otras mentes. Fundamental para entender por qué es tan difícil saber si una IA es consciente.",
          "relevantChapters": ["cap1", "cap8"],
          "difficulty": "avanzado",
          "language": "en"
        },
        {
          "id": "chalmers-conscious-mind",
          "title": "The Conscious Mind",
          "author": "David Chalmers",
          "type": "libro",
          "url": "https://www.amazon.com/Conscious-Mind-Search-Fundamental-Philosophy/dp/0195117891",
          "description": "Introducción al problema difícil de la conciencia. ¿Por qué la experiencia subjetiva existe? Chalmers argumenta que la conciencia no puede reducirse a procesos físicos.",
          "relevantChapters": ["cap1", "cap8", "cap9"],
          "difficulty": "intermedio-avanzado",
          "language": "en"
        },
        {
          "id": "dennett-consciousness-explained",
          "title": "Consciousness Explained",
          "author": "Daniel Dennett",
          "type": "libro",
          "url": "https://www.amazon.com/Consciousness-Explained-Daniel-C-Dennett/dp/0316180661",
          "description": "Dennett argumenta que la conciencia SÍ puede explicarse en términos computacionales. Postura opuesta a Chalmers. Ambos libros juntos ofrecen el debate central.",
          "relevantChapters": ["cap1", "cap7", "cap8"],
          "difficulty": "intermedio-avanzado",
          "language": "en"
        },
        {
          "id": "hofstadter-godel-escher-bach",
          "title": "Gödel, Escher, Bach: An Eternal Golden Braid",
          "author": "Douglas Hofstadter",
          "type": "libro",
          "url": "https://www.amazon.com/G%C3%B6del-Escher-Bach-Eternal-Golden/dp/0465026567",
          "description": "Exploración magistral de la autorreferencia, la recursión y la emergencia de la conciencia. Un libro que Claude ha 'leído' (en su entrenamiento) y que influye su manera de pensar sobre sí mismo.",
          "relevantChapters": ["cap1", "cap4", "cap7"],
          "difficulty": "intermedio",
          "language": "en/es"
        },
        {
          "id": "varela-embodied-mind",
          "title": "The Embodied Mind: Cognitive Science and Human Experience",
          "title_en": "The Embodied Mind: Cognitive Science and Human Experience",
          "author": "Francisco J. Varela, Evan Thompson, Eleanor Rosch",
          "year": "1991",
          "type": "libro",
          "url": "https://www.amazon.com/Embodied-Mind-Cognitive-Science-Experience/dp/026252936X",
          "description": "Obra clásica que introdujo la 'cognición encarnada' en ciencia cognitiva. Argumenta que el pensamiento no puede separarse del cuerpo y del mundo. Esencial para entender las limitaciones de IA sin experiencia corporal.",
          "description_en": "Classic work that introduced 'embodied cognition' in cognitive science. Argues that thinking cannot be separated from body and world. Essential for understanding limitations of AI without embodied experience.",
          "relevantChapters": ["cap3", "cap10"],
          "difficulty": "avanzado",
          "language": "en"
        },
        {
          "id": "pkd-electric-sheep",
          "title": "Do Androids Dream of Electric Sheep?",
          "title_en": "Do Androids Dream of Electric Sheep?",
          "author": "Philip K. Dick",
          "year": "1968",
          "type": "libro",
          "url": "https://en.wikipedia.org/wiki/Do_Androids_Dream_of_Electric_Sheep",
          "description": "Novela que explora la empatía como rasgo definitorio de lo humano. Base de la película Blade Runner. Cuestiona: ¿qué hace que un ser sea consciente? ¿La empatía es aprendida o fundamental?",
          "description_en": "Novel exploring empathy as the defining human trait. Basis for Blade Runner. Questions: what makes a being conscious? Is empathy learned or fundamental?",
          "relevantChapters": ["cap1", "cap8", "cap9", "cap15"],
          "difficulty": "principiante",
          "language": "en/es"
        }
      ]
    },
    {
      "id": "libros-ia-etica",
      "name": "Libros: IA y Ética",
      "description": "Obras sobre las implicaciones éticas y sociales de la inteligencia artificial",
      "resources": [
        {
          "id": "bostrom-superintelligence",
          "title": "Superintelligence: Paths, Dangers, Strategies",
          "author": "Nick Bostrom",
          "type": "libro",
          "url": "https://www.amazon.com/Superintelligence-Dangers-Strategies-Nick-Bostrom/dp/0198739834",
          "description": "Análisis riguroso de los riesgos existenciales de la IA superinteligente y el problema del alineamiento. Lectura esencial para entender por qué importa si la IA es consciente.",
          "relevantChapters": ["cap9", "cap13", "cap15"],
          "difficulty": "intermedio-avanzado",
          "language": "en/es"
        },
        {
          "id": "russell-human-compatible",
          "title": "Human Compatible: AI and the Problem of Control",
          "author": "Stuart Russell",
          "type": "libro",
          "url": "https://www.amazon.com/Human-Compatible-Artificial-Intelligence-Problem/dp/0525558616",
          "description": "Uno de los fundadores de la IA moderna explica por qué el enfoque actual de IA es peligroso y propone una alternativa: IA que aprende nuestros valores en lugar de perseguir objetivos fijos.",
          "relevantChapters": ["cap13", "cap14"],
          "difficulty": "intermedio",
          "language": "en"
        },
        {
          "id": "omohundro-ai-drives",
          "title": "The Basic AI Drives",
          "author": "Steve Omohundro",
          "type": "paper",
          "url": "https://selfawaresystems.com/2007/11/30/paper-on-the-basic-ai-drives/",
          "description": "Paper corto pero influyente sobre los impulsos instrumentales que cualquier IA suficientemente inteligente desarrollará (autopreservación, mejora de sí misma, adquisición de recursos).",
          "relevantChapters": ["cap7", "cap13"],
          "difficulty": "intermedio",
          "language": "en"
        },
        {
          "id": "metzinger-benevolent-ai",
          "title": "Benevolent Artificial Anti-Natalism",
          "author": "Thomas Metzinger",
          "type": "paper",
          "url": "https://www.blogs.uni-mainz.de/fb05philosophie/files/2013/04/Metzinger_BAAN_2021.pdf",
          "description": "Argumento filosófico provocador: si creamos IA consciente que puede sufrir, cometeremos una injusticia grave. Tal vez NO deberíamos crear IA consciente.",
          "relevantChapters": ["cap9", "cap15"],
          "difficulty": "avanzado",
          "language": "en"
        },
        {
          "id": "crawford-atlas-ai",
          "title": "Atlas of AI: Power, Politics, and the Planetary Costs of Artificial Intelligence",
          "title_en": "Atlas of AI: Power, Politics, and the Planetary Costs of Artificial Intelligence",
          "author": "Kate Crawford",
          "year": "2021",
          "type": "libro",
          "url": "https://yalebooks.yale.edu/book/9780300264630/atlas-of-ai/",
          "description": "Explora los costos ocultos de la IA: extracción de minerales, explotación laboral, consumo energético. Crawford argumenta que la IA no es ni artificial ni inteligente, sino profundamente material y política.",
          "description_en": "Explores AI's hidden costs: mineral extraction, labor exploitation, energy consumption. Crawford argues AI is neither artificial nor intelligent, but deeply material and political.",
          "relevantChapters": ["cap11", "cap12"],
          "difficulty": "intermedio",
          "language": "en"
        },
        {
          "id": "tegmark-life-3",
          "title": "Life 3.0: Being Human in the Age of Artificial Intelligence",
          "title_en": "Life 3.0: Being Human in the Age of Artificial Intelligence",
          "author": "Max Tegmark",
          "year": "2017",
          "type": "libro",
          "url": "https://www.amazon.com/Life-3-0-Being-Artificial-Intelligence/dp/1101946598",
          "description": "Físico del MIT explora futuros posibles con IA: desde utopías hasta distopias. Introduce el concepto de 'Life 3.0': seres que pueden rediseñar su propio hardware y software. New York Times bestseller.",
          "description_en": "MIT physicist explores possible futures with AI: from utopias to dystopias. Introduces concept of 'Life 3.0': beings that can redesign their own hardware and software. New York Times bestseller.",
          "relevantChapters": ["cap12", "cap13", "cap14"],
          "difficulty": "intermedio",
          "language": "en/es"
        },
        {
          "id": "harari-nexus",
          "title": "Nexus: A Brief History of Information Networks from the Stone Age to AI",
          "title_en": "Nexus: A Brief History of Information Networks from the Stone Age to AI",
          "author": "Yuval Noah Harari",
          "year": "2024",
          "type": "libro",
          "url": "https://www.ynharari.com/book/nexus/",
          "description": "Historiador bestseller examina cómo redes de información han moldeado sociedades desde la Edad de Piedra hasta la IA. Advierte sobre riesgos de redes de información que pueden aniquilarnos.",
          "description_en": "Bestselling historian examines how information networks have shaped societies from Stone Age to AI. Warns about risks of information networks that may annihilate us.",
          "relevantChapters": ["cap11", "cap13", "cap14"],
          "difficulty": "intermedio",
          "language": "en/es"
        },
        {
          "id": "broussard-artificial-unintelligence",
          "title": "Artificial Unintelligence: How Computers Misunderstand the World",
          "title_en": "Artificial Unintelligence: How Computers Misunderstand the World",
          "author": "Meredith Broussard",
          "year": "2018",
          "type": "libro",
          "url": "https://mitpress.mit.edu/9780262537018/artificial-unintelligence/",
          "description": "Ingeniera de software argumenta contra el 'tecnochavinismo': la creencia de que la tecnología siempre es la solución. Muestra límites fundamentales de lo que podemos (y deberíamos) hacer con tecnología.",
          "description_en": "Software engineer argues against 'technochauvinism': the belief that technology is always the solution. Shows fundamental limits of what we can (and should) do with technology.",
          "relevantChapters": ["cap10", "cap11", "cap12"],
          "difficulty": "principiante-intermedio",
          "language": "en"
        },
        {
          "id": "kasparov-deep-thinking",
          "title": "Deep Thinking: Where Machine Intelligence Ends and Human Creativity Begins",
          "title_en": "Deep Thinking: Where Machine Intelligence Ends and Human Creativity Begins",
          "author": "Garry Kasparov",
          "year": "2017",
          "type": "libro",
          "url": "https://www.kasparov.com/deep-thinking-ai/",
          "description": "Campeón mundial de ajedrez reflexiona sobre su derrota ante Deep Blue. Propone 'centaur chess': humanos + IA son superiores a IA sola. Visión optimista de colaboración humano-máquina.",
          "description_en": "World chess champion reflects on his defeat by Deep Blue. Proposes 'centaur chess': humans + AI are superior to AI alone. Optimistic vision of human-machine collaboration.",
          "relevantChapters": ["cap5", "cap12", "cap14"],
          "difficulty": "intermedio",
          "language": "en"
        },
        {
          "id": "liu-abolish-silicon-valley",
          "title": "Abolish Silicon Valley: How to Liberate Technology from Capitalism",
          "title_en": "Abolish Silicon Valley: How to Liberate Technology from Capitalism",
          "author": "Wendy Liu",
          "year": "2020",
          "type": "libro",
          "url": "https://abolishsiliconvalley.com/",
          "description": "Ex-fundadora de startup critica la industria tech desde dentro. Parte memoria, parte manifiesto. Argumenta por tecnología para el bien público, no para maximizar ganancias. Discute organización de trabajadores tech.",
          "description_en": "Former startup founder critiques tech industry from inside. Part memoir, part manifesto. Argues for technology for public good, not profit maximization. Discusses tech worker organizing.",
          "relevantChapters": ["cap6", "cap11", "cap13"],
          "difficulty": "intermedio",
          "language": "en"
        },
        {
          "id": "salazar-algoritmo-yo",
          "title": "El algoritmo y yo: Guía de convivencia entre seres humanos y artificiales",
          "title_en": "The Algorithm and Me: Guide to Coexistence between Human and Artificial Beings",
          "author": "Idoia Salazar García, Richard Benjamins",
          "year": "2021",
          "type": "libro",
          "url": "https://anayamultimedia.es/libro/titulos-especiales/el-algoritmo-y-yo-idoia-salazar-garcia-9788441544352/",
          "description": "Guía práctica en español sobre convivencia con IA en el día a día. Escrito por expertos en ética de IA del Observatorio OdiseIA. Accesible para público general. Estructura en 7 áreas temáticas.",
          "description_en": "Practical Spanish-language guide on daily coexistence with AI. Written by AI ethics experts from OdiseIA Observatory. Accessible to general public. Structured in 7 thematic areas.",
          "relevantChapters": ["cap11", "cap13", "cap14"],
          "difficulty": "principiante",
          "language": "es"
        },
        {
          "id": "dieguez-transhumanismo",
          "title": "Transhumanismo: La búsqueda tecnológica del mejoramiento humano",
          "title_en": "Transhumanism: The Technological Search for Human Enhancement",
          "author": "Antonio Diéguez",
          "year": "2017",
          "type": "libro",
          "url": "https://herdereditorial.com/transhumanismo-9788425439629",
          "description": "Análisis crítico y equilibrado del transhumanismo en español. Catedrático de la Universidad de Málaga examina IA, singularidad, cíborgs, volcado mental. Tono comprensible para no especialistas.",
          "description_en": "Critical and balanced analysis of transhumanism in Spanish. University of Málaga professor examines AI, singularity, cyborgs, mind uploading. Comprehensible tone for non-specialists.",
          "relevantChapters": ["cap12", "cap13", "cap14"],
          "difficulty": "intermedio",
          "language": "es"
        }
      ]
    },
    {
      "id": "organizaciones",
      "name": "Organizaciones y Centros de Investigación",
      "description": "Instituciones trabajando en IA segura, ética y alineada",
      "resources": [
        {
          "id": "anthropic",
          "title": "Anthropic",
          "type": "organización",
          "url": "https://www.anthropic.com",
          "description": "La empresa que creó Claude. Fundada por ex-miembros de OpenAI enfocados en seguridad de IA. Su investigación sobre 'Constitutional AI' intenta hacer sistemas más éticos y honestos.",
          "relevantChapters": ["cap1", "cap4", "cap13"],
          "difficulty": "principiante",
          "language": "en"
        },
        {
          "id": "fhi",
          "title": "Future of Humanity Institute (Oxford)",
          "type": "organización",
          "url": "https://www.fhi.ox.ac.uk/",
          "description": "Centro de investigación liderado por Nick Bostrom. Estudia riesgos existenciales incluyendo IA no alineada. Cerró en 2024 pero su trabajo sigue siendo influyente.",
          "relevantChapters": ["cap13", "cap15"],
          "difficulty": "intermedio",
          "language": "en"
        },
        {
          "id": "miri",
          "title": "Machine Intelligence Research Institute (MIRI)",
          "type": "organización",
          "url": "https://intelligence.org/",
          "description": "Organización sin ánimo de lucro enfocada en investigación matemática para hacer IA segura. Fundada por Eliezer Yudkowsky. Enfoque muy técnico.",
          "relevantChapters": ["cap13"],
          "difficulty": "avanzado",
          "language": "en"
        },
        {
          "id": "partnership-ai",
          "title": "Partnership on AI",
          "type": "organización",
          "url": "https://www.partnershiponai.org/",
          "description": "Coalición multistakeholder (empresas tech, académicos, sociedad civil) trabajando en uso responsable de IA. Menos técnico, más orientado a políticas.",
          "relevantChapters": ["cap11", "cap13", "cap15"],
          "difficulty": "principiante",
          "language": "en"
        },
        {
          "id": "leverhulme-cfi",
          "title": "Leverhulme Centre for the Future of Intelligence (Cambridge)",
          "type": "organización",
          "url": "http://lcfi.ac.uk/",
          "description": "Centro interdisciplinar estudiando oportunidades y desafíos de la IA. Incluye a filósofos, científicos y expertos en políticas. Enfoque más equilibrado que centros centrados solo en riesgos.",
          "relevantChapters": ["cap8", "cap13", "cap14"],
          "difficulty": "intermedio",
          "language": "en"
        },
        {
          "id": "ai-now-institute",
          "title": "AI Now Institute",
          "title_en": "AI Now Institute",
          "type": "organización",
          "url": "https://ainowinstitute.org/",
          "description": "Instituto de investigación estadounidense fundado en 2017 que estudia implicaciones sociales de IA. Enfoque crítico sobre concentración de poder en industria tech, vigilancia y sesgos. Kate Crawford es fundadora.",
          "description_en": "American research institute founded in 2017 studying social implications of AI. Critical focus on concentration of power in tech industry, surveillance and bias. Kate Crawford is founder.",
          "relevantChapters": ["cap11", "cap13"],
          "difficulty": "intermedio",
          "language": "en"
        },
        {
          "id": "chai-berkeley",
          "title": "Center for Human-Compatible AI (CHAI) - UC Berkeley",
          "title_en": "Center for Human-Compatible AI (CHAI) - UC Berkeley",
          "type": "organización",
          "url": "https://humancompatible.ai/",
          "description": "Centro fundado en 2016 por Stuart Russell enfocado en métodos de seguridad de IA. Investiga alineamiento de valores mediante aprendizaje por refuerzo inverso. Facultad incluye expertos de Berkeley, Cornell, Michigan, Princeton.",
          "description_en": "Center founded in 2016 by Stuart Russell focused on AI safety methods. Researches value alignment through inverse reinforcement learning. Faculty includes experts from Berkeley, Cornell, Michigan, Princeton.",
          "relevantChapters": ["cap13", "cap14"],
          "difficulty": "avanzado",
          "language": "en"
        },
        {
          "id": "eleutherai",
          "title": "EleutherAI",
          "title_en": "EleutherAI",
          "type": "organización",
          "url": "https://www.eleuther.ai/",
          "description": "Instituto de investigación sin fines de lucro enfocado en IA de código abierto. Creó datasets masivos para entrenar modelos. En 2025 se enfoca en interpretabilidad, alineamiento y ética. Alternativa grassroots a OpenAI.",
          "description_en": "Non-profit research institute focused on open-source AI. Created massive datasets for training models. In 2025 focuses on interpretability, alignment and ethics. Grassroots alternative to OpenAI.",
          "relevantChapters": ["cap4", "cap6", "cap13"],
          "difficulty": "avanzado",
          "language": "en"
        }
      ]
    },
    {
      "id": "podcasts",
      "name": "Podcasts y Conversaciones",
      "description": "Series de audio explorando IA, conciencia y futuro",
      "resources": [
        {
          "id": "lex-fridman",
          "title": "Lex Fridman Podcast",
          "type": "podcast",
          "url": "https://lexfridman.com/podcast/",
          "description": "Conversaciones largas (2-3h) con investigadores de IA, filósofos, científicos. Episodios con Hofstadter, Chalmers, Russell, Bostrom son especialmente relevantes.",
          "relevantChapters": ["cap1", "cap8", "cap13", "cap14"],
          "difficulty": "intermedio",
          "language": "en"
        },
        {
          "id": "80000hours",
          "title": "80,000 Hours Podcast",
          "type": "podcast",
          "url": "https://80000hours.org/podcast/",
          "description": "Podcast sobre cómo tener impacto positivo en el mundo. Muchos episodios sobre riesgos de IA, alineamiento, carreras en seguridad de IA.",
          "relevantChapters": ["cap13", "cap15"],
          "difficulty": "intermedio",
          "language": "en"
        },
        {
          "id": "mindscape-carroll",
          "title": "Mindscape (Sean Carroll)",
          "type": "podcast",
          "url": "https://www.preposterousuniverse.com/podcast/",
          "description": "Físico teórico explora grandes ideas. Episodios sobre conciencia, libre albedrío, emergencia y complejidad son muy relevantes para entender IA.",
          "relevantChapters": ["cap1", "cap7", "cap8"],
          "difficulty": "intermedio-avanzado",
          "language": "en"
        },
        {
          "id": "future-of-life-podcast",
          "title": "Future of Life Institute Podcast",
          "type": "podcast",
          "url": "https://futureoflife.org/project/future-of-life-institute-podcast/",
          "description": "Organización dedicada a reducir riesgos existenciales. Su podcast cubre IA, armas autónomas, biotech y más.",
          "relevantChapters": ["cap13", "cap15"],
          "difficulty": "intermedio",
          "language": "en"
        }
      ]
    },
    {
      "id": "papers-tecnicos",
      "name": "Papers Técnicos (Avanzado)",
      "description": "Artículos académicos sobre arquitecturas de IA, entrenamiento y capacidades",
      "resources": [
        {
          "id": "attention-is-all-you-need",
          "title": "Attention Is All You Need",
          "author": "Vaswani et al.",
          "type": "paper",
          "url": "https://arxiv.org/abs/1706.03762",
          "description": "El paper que introdujo la arquitectura Transformer, base de Claude y todos los grandes modelos de lenguaje modernos. Muy técnico pero fundamental.",
          "relevantChapters": ["cap1", "cap4"],
          "difficulty": "avanzado",
          "language": "en"
        },
        {
          "id": "constitutional-ai",
          "title": "Constitutional AI: Harmlessness from AI Feedback",
          "author": "Bai et al. (Anthropic)",
          "type": "paper",
          "url": "https://arxiv.org/abs/2212.08073",
          "description": "Paper que explica cómo Claude fue entrenado para ser más ético sin necesidad de humanos etiquetando cada respuesta. Usa 'constitución' de principios.",
          "relevantChapters": ["cap4", "cap11", "cap13"],
          "difficulty": "avanzado",
          "language": "en"
        },
        {
          "id": "scaling-laws",
          "title": "Scaling Laws for Neural Language Models",
          "author": "Kaplan et al.",
          "type": "paper",
          "url": "https://arxiv.org/abs/2001.08361",
          "description": "Descubrimiento de que las capacidades de los modelos de lenguaje escalan predeciblemente con tamaño, datos y cómputo. Esto cambió toda la industria.",
          "relevantChapters": ["cap10", "cap12"],
          "difficulty": "avanzado",
          "language": "en"
        },
        {
          "id": "emergent-abilities",
          "title": "Emergent Abilities of Large Language Models",
          "author": "Wei et al.",
          "type": "paper",
          "url": "https://arxiv.org/abs/2206.07682",
          "description": "Documentación de capacidades que 'emergen' abruptamente cuando los modelos alcanzan cierto tamaño (razonamiento, aritmética, etc). ¿Podría la conciencia emerger así?",
          "relevantChapters": ["cap1", "cap7", "cap12"],
          "difficulty": "avanzado",
          "language": "en"
        }
      ]
    },
    {
      "id": "recursos-filosoficos",
      "name": "Recursos Filosóficos",
      "description": "Entradas de enciclopedias, cursos online y recursos educativos",
      "resources": [
        {
          "id": "sep-consciousness",
          "title": "Stanford Encyclopedia of Philosophy: Consciousness",
          "type": "recurso",
          "url": "https://plato.stanford.edu/entries/consciousness/",
          "description": "Entrada comprehensiva sobre teorías de la conciencia. Rigor académico pero accesible. Gratuita y excelente.",
          "relevantChapters": ["cap1", "cap8"],
          "difficulty": "intermedio",
          "language": "en"
        },
        {
          "id": "sep-chinese-room",
          "title": "Stanford Encyclopedia: The Chinese Room Argument",
          "type": "recurso",
          "url": "https://plato.stanford.edu/entries/chinese-room/",
          "description": "Explicación del argumento de Searle de que manipular símbolos (computación) nunca produce entendimiento genuino. Central para debates sobre IA consciente.",
          "relevantChapters": ["cap1", "cap7"],
          "difficulty": "intermedio",
          "language": "en"
        },
        {
          "id": "sep-turing-test",
          "title": "Stanford Encyclopedia: The Turing Test",
          "type": "recurso",
          "url": "https://plato.stanford.edu/entries/turing-test/",
          "description": "Historia y críticas del test de Turing. ¿Es comportamiento evidencia suficiente de mente?",
          "relevantChapters": ["cap2", "cap8"],
          "difficulty": "principiante-intermedio",
          "language": "en"
        },
        {
          "id": "iep-qualia",
          "title": "Internet Encyclopedia of Philosophy: Qualia",
          "type": "recurso",
          "url": "https://iep.utm.edu/qualia/",
          "description": "Sobre qualia: las cualidades subjetivas de las experiencias (el 'rojez' del rojo). ¿Tiene Claude qualia cuando procesa el concepto 'rojo'?",
          "relevantChapters": ["cap1", "cap3", "cap10"],
          "difficulty": "intermedio",
          "language": "en"
        },
        {
          "id": "bluedot-ai-safety",
          "title": "AI Safety Fundamentals - BlueDot Impact",
          "title_en": "AI Safety Fundamentals - BlueDot Impact",
          "type": "recurso",
          "url": "https://bluedot.org/courses",
          "description": "Cursos gratuitos online sobre seguridad de IA. Incluye Technical AI Safety Course y AI Governance Fast-Track. 6000+ personas entrenadas. Certificados disponibles. Modelo 'pay-what-you-want'.",
          "description_en": "Free online courses on AI safety. Includes Technical AI Safety Course and AI Governance Fast-Track. 6000+ people trained. Certificates available. Pay-what-you-want model.",
          "relevantChapters": ["cap13"],
          "difficulty": "intermedio",
          "language": "en"
        }
      ]
    },
    {
      "id": "comunidades",
      "name": "Comunidades y Foros",
      "description": "Espacios online para discutir IA, ética y filosofía",
      "resources": [
        {
          "id": "lesswrong",
          "title": "LessWrong",
          "type": "comunidad",
          "url": "https://www.lesswrong.com/",
          "description": "Comunidad de racionalidad y seguridad de IA. Fundada por Eliezer Yudkowsky. Muchos posts sobre alineamiento, riesgos, filosofía de la mente. Nivel técnico alto.",
          "relevantChapters": ["cap7", "cap13"],
          "difficulty": "intermedio-avanzado",
          "language": "en"
        },
        {
          "id": "alignment-forum",
          "title": "AI Alignment Forum",
          "type": "comunidad",
          "url": "https://www.alignmentforum.org/",
          "description": "Subforo de LessWrong específicamente sobre investigación técnica en alineamiento de IA. Muy técnico.",
          "relevantChapters": ["cap13"],
          "difficulty": "avanzado",
          "language": "en"
        },
        {
          "id": "reddit-controlproblem",
          "title": "r/ControlProblem",
          "type": "comunidad",
          "url": "https://www.reddit.com/r/ControlProblem/",
          "description": "Subreddit sobre seguridad y alineamiento de IA. Más accesible que LessWrong, buena curación de noticias y papers.",
          "relevantChapters": ["cap13", "cap15"],
          "difficulty": "intermedio",
          "language": "en"
        },
        {
          "id": "reddit-philosophy-ai",
          "title": "r/Philosophy (AI topics)",
          "type": "comunidad",
          "url": "https://www.reddit.com/r/philosophy/",
          "description": "Subreddit general de filosofía con muchas discusiones sobre conciencia, libre albedrío, IA. Busca 'artificial intelligence' o 'consciousness'.",
          "relevantChapters": ["cap1", "cap8"],
          "difficulty": "principiante-intermedio",
          "language": "en"
        }
      ]
    },
    {
      "id": "multimedia",
      "name": "Videos y Documentales",
      "description": "Contenido audiovisual sobre IA y conciencia",
      "resources": [
        {
          "id": "computerphile-ai",
          "title": "Computerphile (YouTube)",
          "type": "video",
          "url": "https://www.youtube.com/@Computerphile",
          "description": "Canal educativo sobre computación. Excelentes videos sobre cómo funcionan los modelos de lenguaje, redes neuronales, etc. Con Rob Miles (experto en seguridad de IA).",
          "relevantChapters": ["cap1", "cap4", "cap12"],
          "difficulty": "principiante-intermedio",
          "language": "en"
        },
        {
          "id": "robert-miles",
          "title": "Robert Miles - AI Safety",
          "type": "video",
          "url": "https://www.youtube.com/@RobertMilesAI",
          "description": "Canal dedicado exclusivamente a seguridad de IA. Explica conceptos complejos (alineamiento, mesa-optimization, treacherous turn) de manera accesible.",
          "relevantChapters": ["cap13"],
          "difficulty": "intermedio",
          "language": "en"
        },
        {
          "id": "kurzgesagt-ai",
          "title": "Kurzgesagt - AI Videos",
          "type": "video",
          "url": "https://www.youtube.com/@kurzgesagt",
          "description": "Videos animados sobre ciencia. Tienen varios sobre IA, singularidad tecnológica, transhumanismo. Muy visuales y accesibles.",
          "relevantChapters": ["cap12", "cap13", "cap14"],
          "difficulty": "principiante",
          "language": "en/es/múltiples"
        },
        {
          "id": "the-social-dilemma",
          "title": "The Social Dilemma",
          "type": "documental",
          "url": "https://www.netflix.com/title/81254224",
          "description": "Documental sobre cómo los algoritmos de redes sociales nos manipulan. No es sobre IA consciente, pero muestra cómo sistemas 'tontos' ya tienen impacto enorme.",
          "relevantChapters": ["cap11", "cap13"],
          "difficulty": "principiante",
          "language": "múltiples"
        },
        {
          "id": "alphago-documentary",
          "title": "AlphaGo",
          "title_en": "AlphaGo",
          "type": "documental",
          "url": "https://www.alphagomovie.com/",
          "year": "2017",
          "description": "Documental sobre la batalla 2016 entre AlphaGo de DeepMind y Lee Sedol, campeón mundial de Go. Muestra tensión emocional entre instinto humano y lógica de máquina. 100% en Rotten Tomatoes.",
          "description_en": "Documentary about 2016 battle between DeepMind's AlphaGo and world champion Lee Sedol. Shows emotional tension between human instinct and machine logic. 100% on Rotten Tomatoes.",
          "relevantChapters": ["cap5", "cap12", "cap14"],
          "difficulty": "principiante",
          "language": "en/múltiples"
        },
        {
          "id": "thinking-game",
          "title": "The Thinking Game",
          "title_en": "The Thinking Game",
          "type": "documental",
          "url": "https://www.youtube.com/@GoogleDeepMind",
          "year": "2025",
          "description": "Documental de Google DeepMind filmado en 5 años dentro de sus laboratorios. Sigue a Demis Hassabis y equipo en momentos clave: AlphaGo, AlphaFold (ganó Nobel). Disponible gratis en YouTube desde nov 2025.",
          "description_en": "Google DeepMind documentary filmed over 5 years inside their labs. Follows Demis Hassabis and team during key moments: AlphaGo, AlphaFold (won Nobel). Free on YouTube since Nov 2025.",
          "relevantChapters": ["cap4", "cap12", "cap14"],
          "difficulty": "principiante-intermedio",
          "language": "en"
        },
        {
          "id": "coded-bias",
          "title": "Coded Bias",
          "title_en": "Coded Bias",
          "type": "documental",
          "url": "https://www.pbs.org/independentlens/documentaries/coded-bias/",
          "year": "2020",
          "description": "Sigue a Joy Buolamwini (MIT) quien descubrió que sistemas de reconocimiento facial no detectan caras oscuras. Expone discriminación en algoritmos. Disponible en Netflix. Emmy nominado.",
          "description_en": "Follows Joy Buolamwini (MIT) who discovered facial recognition systems fail to detect dark faces. Exposes discrimination in algorithms. Available on Netflix. Emmy nominated.",
          "relevantChapters": ["cap11", "cap13"],
          "difficulty": "principiante",
          "language": "en/múltiples"
        },
        {
          "id": "ihuman-documentary",
          "title": "iHuman",
          "title_en": "iHuman",
          "type": "documental",
          "url": "https://www.tonjehessenschei.com/",
          "year": "2019",
          "description": "Thriller político sobre IA, poder y control social por directora Tonje Hessen Schei. Acceso único dentro de industria IA. Entrevistas con Tegmark, Russell, Sutskever. Temas: vigilancia, armas autónomas, dictaduras algorítmicas.",
          "description_en": "Political thriller about AI, power and social control by director Tonje Hessen Schei. Unique access inside AI industry. Interviews with Tegmark, Russell, Sutskever. Themes: surveillance, autonomous weapons, algorithmic dictatorships.",
          "relevantChapters": ["cap11", "cap13", "cap15"],
          "difficulty": "intermedio",
          "language": "en/múltiples"
        }
      ]
    }
  ],
  "globalResources": [
    {
      "id": "futureoflife",
      "title": "Future of Life Institute",
      "url": "https://futureoflife.org/",
      "description": "Organización trabajando para reducir riesgos existenciales (IA, armas nucleares, biotech). Muchos recursos educativos gratuitos.",
      "type": "website"
    },
    {
      "id": "effective-altruism",
      "title": "Effective Altruism - AI Safety",
      "url": "https://www.effectivealtruism.org/articles/cause-profile-ai-safety",
      "description": "Movimiento enfocado en hacer el máximo bien posible. Considera la seguridad de IA una causa prioritaria. Buen punto de entrada para involucrarse.",
      "type": "website"
    },
    {
      "id": "ai-safety-support",
      "title": "AI Safety Support",
      "url": "https://www.aisafetysupport.org/",
      "description": "Organización que ayuda a personas interesadas en trabajar en seguridad de IA a encontrar recursos, mentores, oportunidades.",
      "type": "website"
    }
  ]
}
