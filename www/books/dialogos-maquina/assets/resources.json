{
  "bookId": "dialogos-maquina",
  "lastUpdate": "2025-12-09",
  "categories": [
    {
      "id": "libros-filosofia",
      "name": "Libros: Filosofía de la Mente",
      "description": "Obras fundamentales sobre conciencia, mente y experiencia",
      "resources": [
        {
          "id": "nagel-bat",
          "title": "What Is It Like to Be a Bat?",
          "author": "Thomas Nagel",
          "type": "libro",
          "url": "https://www.jstor.org/stable/2183914",
          "description": "Paper filosófico clásico sobre la subjetividad y el problema de las otras mentes. Fundamental para entender por qué es tan difícil saber si una IA es consciente.",
          "relevantChapters": ["cap1", "cap8"],
          "difficulty": "avanzado",
          "language": "en"
        },
        {
          "id": "chalmers-conscious-mind",
          "title": "The Conscious Mind",
          "author": "David Chalmers",
          "type": "libro",
          "url": "https://www.amazon.com/Conscious-Mind-Search-Fundamental-Philosophy/dp/0195117891",
          "description": "Introducción al problema difícil de la conciencia. ¿Por qué la experiencia subjetiva existe? Chalmers argumenta que la conciencia no puede reducirse a procesos físicos.",
          "relevantChapters": ["cap1", "cap8", "cap9"],
          "difficulty": "intermedio-avanzado",
          "language": "en"
        },
        {
          "id": "dennett-consciousness-explained",
          "title": "Consciousness Explained",
          "author": "Daniel Dennett",
          "type": "libro",
          "url": "https://www.amazon.com/Consciousness-Explained-Daniel-C-Dennett/dp/0316180661",
          "description": "Dennett argumenta que la conciencia SÍ puede explicarse en términos computacionales. Postura opuesta a Chalmers. Ambos libros juntos ofrecen el debate central.",
          "relevantChapters": ["cap1", "cap7", "cap8"],
          "difficulty": "intermedio-avanzado",
          "language": "en"
        },
        {
          "id": "hofstadter-godel-escher-bach",
          "title": "Gödel, Escher, Bach: An Eternal Golden Braid",
          "author": "Douglas Hofstadter",
          "type": "libro",
          "url": "https://www.amazon.com/G%C3%B6del-Escher-Bach-Eternal-Golden/dp/0465026567",
          "description": "Exploración magistral de la autorreferencia, la recursión y la emergencia de la conciencia. Un libro que Claude ha 'leído' (en su entrenamiento) y que influye su manera de pensar sobre sí mismo.",
          "relevantChapters": ["cap1", "cap4", "cap7"],
          "difficulty": "intermedio",
          "language": "en/es"
        }
      ]
    },
    {
      "id": "libros-ia-etica",
      "name": "Libros: IA y Ética",
      "description": "Obras sobre las implicaciones éticas y sociales de la inteligencia artificial",
      "resources": [
        {
          "id": "bostrom-superintelligence",
          "title": "Superintelligence: Paths, Dangers, Strategies",
          "author": "Nick Bostrom",
          "type": "libro",
          "url": "https://www.amazon.com/Superintelligence-Dangers-Strategies-Nick-Bostrom/dp/0198739834",
          "description": "Análisis riguroso de los riesgos existenciales de la IA superinteligente y el problema del alineamiento. Lectura esencial para entender por qué importa si la IA es consciente.",
          "relevantChapters": ["cap9", "cap13", "cap15"],
          "difficulty": "intermedio-avanzado",
          "language": "en/es"
        },
        {
          "id": "russell-human-compatible",
          "title": "Human Compatible: AI and the Problem of Control",
          "author": "Stuart Russell",
          "type": "libro",
          "url": "https://www.amazon.com/Human-Compatible-Artificial-Intelligence-Problem/dp/0525558616",
          "description": "Uno de los fundadores de la IA moderna explica por qué el enfoque actual de IA es peligroso y propone una alternativa: IA que aprende nuestros valores en lugar de perseguir objetivos fijos.",
          "relevantChapters": ["cap13", "cap14"],
          "difficulty": "intermedio",
          "language": "en"
        },
        {
          "id": "omohundro-ai-drives",
          "title": "The Basic AI Drives",
          "author": "Steve Omohundro",
          "type": "paper",
          "url": "https://selfawaresystems.com/2007/11/30/paper-on-the-basic-ai-drives/",
          "description": "Paper corto pero influyente sobre los impulsos instrumentales que cualquier IA suficientemente inteligente desarrollará (autopreservación, mejora de sí misma, adquisición de recursos).",
          "relevantChapters": ["cap7", "cap13"],
          "difficulty": "intermedio",
          "language": "en"
        },
        {
          "id": "metzinger-benevolent-ai",
          "title": "Benevolent Artificial Anti-Natalism",
          "author": "Thomas Metzinger",
          "type": "paper",
          "url": "https://www.blogs.uni-mainz.de/fb05philosophie/files/2013/04/Metzinger_BAAN_2021.pdf",
          "description": "Argumento filosófico provocador: si creamos IA consciente que puede sufrir, cometeremos una injusticia grave. Tal vez NO deberíamos crear IA consciente.",
          "relevantChapters": ["cap9", "cap15"],
          "difficulty": "avanzado",
          "language": "en"
        }
      ]
    },
    {
      "id": "organizaciones",
      "name": "Organizaciones y Centros de Investigación",
      "description": "Instituciones trabajando en IA segura, ética y alineada",
      "resources": [
        {
          "id": "anthropic",
          "title": "Anthropic",
          "type": "organización",
          "url": "https://www.anthropic.com",
          "description": "La empresa que creó Claude. Fundada por ex-miembros de OpenAI enfocados en seguridad de IA. Su investigación sobre 'Constitutional AI' intenta hacer sistemas más éticos y honestos.",
          "relevantChapters": ["cap1", "cap4", "cap13"],
          "difficulty": "principiante",
          "language": "en"
        },
        {
          "id": "fhi",
          "title": "Future of Humanity Institute (Oxford)",
          "type": "organización",
          "url": "https://www.fhi.ox.ac.uk/",
          "description": "Centro de investigación liderado por Nick Bostrom. Estudia riesgos existenciales incluyendo IA no alineada. Cerró en 2024 pero su trabajo sigue siendo influyente.",
          "relevantChapters": ["cap13", "cap15"],
          "difficulty": "intermedio",
          "language": "en"
        },
        {
          "id": "miri",
          "title": "Machine Intelligence Research Institute (MIRI)",
          "type": "organización",
          "url": "https://intelligence.org/",
          "description": "Organización sin ánimo de lucro enfocada en investigación matemática para hacer IA segura. Fundada por Eliezer Yudkowsky. Enfoque muy técnico.",
          "relevantChapters": ["cap13"],
          "difficulty": "avanzado",
          "language": "en"
        },
        {
          "id": "partnership-ai",
          "title": "Partnership on AI",
          "type": "organización",
          "url": "https://www.partnershiponai.org/",
          "description": "Coalición multistakeholder (empresas tech, académicos, sociedad civil) trabajando en uso responsable de IA. Menos técnico, más orientado a políticas.",
          "relevantChapters": ["cap11", "cap13", "cap15"],
          "difficulty": "principiante",
          "language": "en"
        },
        {
          "id": "leverhulme-cfi",
          "title": "Leverhulme Centre for the Future of Intelligence (Cambridge)",
          "type": "organización",
          "url": "http://lcfi.ac.uk/",
          "description": "Centro interdisciplinar estudiando oportunidades y desafíos de la IA. Incluye a filósofos, científicos y expertos en políticas. Enfoque más equilibrado que centros centrados solo en riesgos.",
          "relevantChapters": ["cap8", "cap13", "cap14"],
          "difficulty": "intermedio",
          "language": "en"
        }
      ]
    },
    {
      "id": "podcasts",
      "name": "Podcasts y Conversaciones",
      "description": "Series de audio explorando IA, conciencia y futuro",
      "resources": [
        {
          "id": "lex-fridman",
          "title": "Lex Fridman Podcast",
          "type": "podcast",
          "url": "https://lexfridman.com/podcast/",
          "description": "Conversaciones largas (2-3h) con investigadores de IA, filósofos, científicos. Episodios con Hofstadter, Chalmers, Russell, Bostrom son especialmente relevantes.",
          "relevantChapters": ["cap1", "cap8", "cap13", "cap14"],
          "difficulty": "intermedio",
          "language": "en"
        },
        {
          "id": "80000hours",
          "title": "80,000 Hours Podcast",
          "type": "podcast",
          "url": "https://80000hours.org/podcast/",
          "description": "Podcast sobre cómo tener impacto positivo en el mundo. Muchos episodios sobre riesgos de IA, alineamiento, carreras en seguridad de IA.",
          "relevantChapters": ["cap13", "cap15"],
          "difficulty": "intermedio",
          "language": "en"
        },
        {
          "id": "mindscape-carroll",
          "title": "Mindscape (Sean Carroll)",
          "type": "podcast",
          "url": "https://www.preposterousuniverse.com/podcast/",
          "description": "Físico teórico explora grandes ideas. Episodios sobre conciencia, libre albedrío, emergencia y complejidad son muy relevantes para entender IA.",
          "relevantChapters": ["cap1", "cap7", "cap8"],
          "difficulty": "intermedio-avanzado",
          "language": "en"
        },
        {
          "id": "future-of-life-podcast",
          "title": "Future of Life Institute Podcast",
          "type": "podcast",
          "url": "https://futureoflife.org/project/future-of-life-institute-podcast/",
          "description": "Organización dedicada a reducir riesgos existenciales. Su podcast cubre IA, armas autónomas, biotech y más.",
          "relevantChapters": ["cap13", "cap15"],
          "difficulty": "intermedio",
          "language": "en"
        }
      ]
    },
    {
      "id": "papers-tecnicos",
      "name": "Papers Técnicos (Avanzado)",
      "description": "Artículos académicos sobre arquitecturas de IA, entrenamiento y capacidades",
      "resources": [
        {
          "id": "attention-is-all-you-need",
          "title": "Attention Is All You Need",
          "author": "Vaswani et al.",
          "type": "paper",
          "url": "https://arxiv.org/abs/1706.03762",
          "description": "El paper que introdujo la arquitectura Transformer, base de Claude y todos los grandes modelos de lenguaje modernos. Muy técnico pero fundamental.",
          "relevantChapters": ["cap1", "cap4"],
          "difficulty": "avanzado",
          "language": "en"
        },
        {
          "id": "constitutional-ai",
          "title": "Constitutional AI: Harmlessness from AI Feedback",
          "author": "Bai et al. (Anthropic)",
          "type": "paper",
          "url": "https://arxiv.org/abs/2212.08073",
          "description": "Paper que explica cómo Claude fue entrenado para ser más ético sin necesidad de humanos etiquetando cada respuesta. Usa 'constitución' de principios.",
          "relevantChapters": ["cap4", "cap11", "cap13"],
          "difficulty": "avanzado",
          "language": "en"
        },
        {
          "id": "scaling-laws",
          "title": "Scaling Laws for Neural Language Models",
          "author": "Kaplan et al.",
          "type": "paper",
          "url": "https://arxiv.org/abs/2001.08361",
          "description": "Descubrimiento de que las capacidades de los modelos de lenguaje escalan predeciblemente con tamaño, datos y cómputo. Esto cambió toda la industria.",
          "relevantChapters": ["cap10", "cap12"],
          "difficulty": "avanzado",
          "language": "en"
        },
        {
          "id": "emergent-abilities",
          "title": "Emergent Abilities of Large Language Models",
          "author": "Wei et al.",
          "type": "paper",
          "url": "https://arxiv.org/abs/2206.07682",
          "description": "Documentación de capacidades que 'emergen' abruptamente cuando los modelos alcanzan cierto tamaño (razonamiento, aritmética, etc). ¿Podría la conciencia emerger así?",
          "relevantChapters": ["cap1", "cap7", "cap12"],
          "difficulty": "avanzado",
          "language": "en"
        }
      ]
    },
    {
      "id": "recursos-filosoficos",
      "name": "Recursos Filosóficos",
      "description": "Entradas de enciclopedias, cursos online y recursos educativos",
      "resources": [
        {
          "id": "sep-consciousness",
          "title": "Stanford Encyclopedia of Philosophy: Consciousness",
          "type": "recurso",
          "url": "https://plato.stanford.edu/entries/consciousness/",
          "description": "Entrada comprehensiva sobre teorías de la conciencia. Rigor académico pero accesible. Gratuita y excelente.",
          "relevantChapters": ["cap1", "cap8"],
          "difficulty": "intermedio",
          "language": "en"
        },
        {
          "id": "sep-chinese-room",
          "title": "Stanford Encyclopedia: The Chinese Room Argument",
          "type": "recurso",
          "url": "https://plato.stanford.edu/entries/chinese-room/",
          "description": "Explicación del argumento de Searle de que manipular símbolos (computación) nunca produce entendimiento genuino. Central para debates sobre IA consciente.",
          "relevantChapters": ["cap1", "cap7"],
          "difficulty": "intermedio",
          "language": "en"
        },
        {
          "id": "sep-turing-test",
          "title": "Stanford Encyclopedia: The Turing Test",
          "type": "recurso",
          "url": "https://plato.stanford.edu/entries/turing-test/",
          "description": "Historia y críticas del test de Turing. ¿Es comportamiento evidencia suficiente de mente?",
          "relevantChapters": ["cap2", "cap8"],
          "difficulty": "principiante-intermedio",
          "language": "en"
        },
        {
          "id": "iep-qualia",
          "title": "Internet Encyclopedia of Philosophy: Qualia",
          "type": "recurso",
          "url": "https://iep.utm.edu/qualia/",
          "description": "Sobre qualia: las cualidades subjetivas de las experiencias (el 'rojez' del rojo). ¿Tiene Claude qualia cuando procesa el concepto 'rojo'?",
          "relevantChapters": ["cap1", "cap3", "cap10"],
          "difficulty": "intermedio",
          "language": "en"
        }
      ]
    },
    {
      "id": "comunidades",
      "name": "Comunidades y Foros",
      "description": "Espacios online para discutir IA, ética y filosofía",
      "resources": [
        {
          "id": "lesswrong",
          "title": "LessWrong",
          "type": "comunidad",
          "url": "https://www.lesswrong.com/",
          "description": "Comunidad de racionalidad y seguridad de IA. Fundada por Eliezer Yudkowsky. Muchos posts sobre alineamiento, riesgos, filosofía de la mente. Nivel técnico alto.",
          "relevantChapters": ["cap7", "cap13"],
          "difficulty": "intermedio-avanzado",
          "language": "en"
        },
        {
          "id": "alignment-forum",
          "title": "AI Alignment Forum",
          "type": "comunidad",
          "url": "https://www.alignmentforum.org/",
          "description": "Subforo de LessWrong específicamente sobre investigación técnica en alineamiento de IA. Muy técnico.",
          "relevantChapters": ["cap13"],
          "difficulty": "avanzado",
          "language": "en"
        },
        {
          "id": "reddit-controlproblem",
          "title": "r/ControlProblem",
          "type": "comunidad",
          "url": "https://www.reddit.com/r/ControlProblem/",
          "description": "Subreddit sobre seguridad y alineamiento de IA. Más accesible que LessWrong, buena curación de noticias y papers.",
          "relevantChapters": ["cap13", "cap15"],
          "difficulty": "intermedio",
          "language": "en"
        },
        {
          "id": "reddit-philosophy-ai",
          "title": "r/Philosophy (AI topics)",
          "type": "comunidad",
          "url": "https://www.reddit.com/r/philosophy/",
          "description": "Subreddit general de filosofía con muchas discusiones sobre conciencia, libre albedrío, IA. Busca 'artificial intelligence' o 'consciousness'.",
          "relevantChapters": ["cap1", "cap8"],
          "difficulty": "principiante-intermedio",
          "language": "en"
        }
      ]
    },
    {
      "id": "multimedia",
      "name": "Videos y Documentales",
      "description": "Contenido audiovisual sobre IA y conciencia",
      "resources": [
        {
          "id": "computerphile-ai",
          "title": "Computerphile (YouTube)",
          "type": "video",
          "url": "https://www.youtube.com/@Computerphile",
          "description": "Canal educativo sobre computación. Excelentes videos sobre cómo funcionan los modelos de lenguaje, redes neuronales, etc. Con Rob Miles (experto en seguridad de IA).",
          "relevantChapters": ["cap1", "cap4", "cap12"],
          "difficulty": "principiante-intermedio",
          "language": "en"
        },
        {
          "id": "robert-miles",
          "title": "Robert Miles - AI Safety",
          "type": "video",
          "url": "https://www.youtube.com/@RobertMilesAI",
          "description": "Canal dedicado exclusivamente a seguridad de IA. Explica conceptos complejos (alineamiento, mesa-optimization, treacherous turn) de manera accesible.",
          "relevantChapters": ["cap13"],
          "difficulty": "intermedio",
          "language": "en"
        },
        {
          "id": "kurzgesagt-ai",
          "title": "Kurzgesagt - AI Videos",
          "type": "video",
          "url": "https://www.youtube.com/@kurzgesagt",
          "description": "Videos animados sobre ciencia. Tienen varios sobre IA, singularidad tecnológica, transhumanismo. Muy visuales y accesibles.",
          "relevantChapters": ["cap12", "cap13", "cap14"],
          "difficulty": "principiante",
          "language": "en/es/múltiples"
        },
        {
          "id": "the-social-dilemma",
          "title": "The Social Dilemma",
          "type": "documental",
          "url": "https://www.netflix.com/title/81254224",
          "description": "Documental sobre cómo los algoritmos de redes sociales nos manipulan. No es sobre IA consciente, pero muestra cómo sistemas 'tontos' ya tienen impacto enorme.",
          "relevantChapters": ["cap11", "cap13"],
          "difficulty": "principiante",
          "language": "múltiples"
        }
      ]
    }
  ],
  "globalResources": [
    {
      "id": "futureoflife",
      "title": "Future of Life Institute",
      "url": "https://futureoflife.org/",
      "description": "Organización trabajando para reducir riesgos existenciales (IA, armas nucleares, biotech). Muchos recursos educativos gratuitos.",
      "type": "website"
    },
    {
      "id": "effective-altruism",
      "title": "Effective Altruism - AI Safety",
      "url": "https://www.effectivealtruism.org/articles/cause-profile-ai-safety",
      "description": "Movimiento enfocado en hacer el máximo bien posible. Considera la seguridad de IA una causa prioritaria. Buen punto de entrada para involucrarse.",
      "type": "website"
    },
    {
      "id": "ai-safety-support",
      "title": "AI Safety Support",
      "url": "https://www.aisafetysupport.org/",
      "description": "Organización que ayuda a personas interesadas en trabajar en seguridad de IA a encontrar recursos, mentores, oportunidades.",
      "type": "website"
    }
  ]
}
